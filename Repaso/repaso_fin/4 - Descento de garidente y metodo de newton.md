### Review
En funciones multivariable, la derivada depende de cada una de las derivadas
Se las llamad erivadas parciales o direcciones, y el vector de todas ellas es el gradiente
$$ D_v f(x) = <\triangledown f(x),v> $$
El graiente normalizado marca la direccion de mayor crecimiento
Las direcciones ortogonales a la de maximo crecimenot, presentan un crecimiento de 0

## Condiciones de optimalidad
#### Condicion necesaia de primer orden para extrema local:
Un pto x_0 es un extremun, (maximo o minimo), si es completamente difereciable, alrederodr de x_0, y su gradiente es 0

#### Consicioens suficiente de segundo orde suficiente para minima local
Si el gradiente es 0 en un pto x0, y la segurnda derivada o Hessiana D^2 es positiva definitiva, x_0 es un minimo local.

Pero, como se encunetran estos ptos?
# Algoritmos de busquade de linea
